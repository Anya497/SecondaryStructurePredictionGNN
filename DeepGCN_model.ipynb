{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27f466d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch.nn.functional as F\n",
    "# from ogb.nodeproppred import Evaluator, PygNodePropPredDataset\n",
    "from torch.nn import LayerNorm, Linear, ReLU\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GCNConv, GatedGraphConv\n",
    "from torch_geometric.nn import DeepGCNLayer, GENConv\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from dataset_processing import RNADataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a077c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = RNADataset(root=\"./data/\")\n",
    "dataset = dataset.shuffle()\n",
    "train_data, val_data, test_data = dataset[0:655], dataset[655:873], dataset[873:]\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=8, shuffle=False)\n",
    "val_dataloader = DataLoader(val_data, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c8ab40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_diags(y):\n",
    "    main_diag = torch.ones([1, y.size(0)])\n",
    "    diag1 = torch.ones([1, y.size(0) - 1])\n",
    "    return y * (torch.diag_embed(main_diag).to(device) + \n",
    "            torch.diag_embed(diag1, offset=1).to(device) + \n",
    "            torch.diag_embed(diag1, offset=-1).to(device) - 1) * (-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a1b581d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_pred, y_true):\n",
    "    y_pred = del_diags(y_pred)\n",
    "    y_pred[(y_pred > 0.5)] = 1\n",
    "    y_pred[(y_pred <= 0.5)] = 0 \n",
    "    \n",
    "    tp = torch.sum(y_pred * y_true)\n",
    "    fp = torch.sum((1 - y_true) * y_pred)\n",
    "    \n",
    "    return tp / (tp + fp + epsilon)\n",
    "\n",
    "def recall(y_pred, y_true):\n",
    "    y_pred = del_diags(y_pred)\n",
    "    y_pred[(y_pred > 0.5)] = 1\n",
    "    y_pred[(y_pred <= 0.5)] = 0\n",
    "    \n",
    "    tp = torch.sum(y_pred * y_true)\n",
    "    fn = torch.sum(y_true * (1 - y_pred))\n",
    "    \n",
    "    return tp / (tp + fn + epsilon)\n",
    "\n",
    "def f_loss(y_pred, y_true):\n",
    "    y_pred = del_diags(y_pred)\n",
    "\n",
    "    tp = torch.sum(y_pred * y_true)\n",
    "    fn = torch.sum(y_true * (1 - y_pred))\n",
    "    fp = torch.sum((1 - y_true) * y_pred)\n",
    "    precision = tp / (tp + fp + epsilon)\n",
    "    recall = tp / (tp + fn + epsilon)\n",
    "\n",
    "    k = 1\n",
    "    k1 = 1 - torch.abs(precision - recall)\n",
    "\n",
    "#     k2 = 1 - torch.abs(K.mean(precision) - K.mean(recall))\n",
    "    #calculate upgraded f1 score\n",
    "    f1 = ((1 + k * k) * precision * recall) / (k * k * precision + recall + epsilon)\n",
    "#     tw = K.sum(K.cast(y_true * y_pred, ’float32’), axis=[1, 2, 3])\n",
    "#     fw = K.sum(K.cast((1 - y_true) * y_pred, ’float32’), axis=[1, 2, 3])\n",
    "#     fb = K.sum(K.cast(y_true * (1 - y_pred), ’float32’), axis=[1, 2, 3])\n",
    "    return 1 - f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34be5809",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepGCNModel(torch.nn.Module):\n",
    "    def __init__(self, num_layers, out_channels):\n",
    "        super(DeepGCNModel, self).__init__()\n",
    "        self.node_encoder = Linear(dataset.num_features, hidden_channels)\n",
    "#         self.edge_encoder = Linear(train_data.edge_attr.size(-1), hidden_channels)\n",
    "\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for i in range(1, num_layers + 1):\n",
    "            conv = GENConv(hidden_channels, hidden_channels, aggr='softmax',\n",
    "                           t=1.0, learn_t=True, num_layers=2, norm='layer')\n",
    "            norm = LayerNorm(hidden_channels, elementwise_affine=True)\n",
    "            act = ReLU(inplace=True)\n",
    "\n",
    "            layer = DeepGCNLayer(conv, norm, act, block='res+', dropout=0.1,\n",
    "                                 ckpt_grad=i % 3)\n",
    "            self.layers.append(layer)\n",
    "\n",
    "#         self.lin = Linear(hidden_channels, data.y.size(-1))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.node_encoder(x)\n",
    "#         edge_attr = self.edge_encoder(edge_attr)\n",
    "\n",
    "        x = self.layers[0].conv(x, edge_index)\n",
    "\n",
    "        for layer in self.layers[1:]:\n",
    "            x = layer(x, edge_index)\n",
    "\n",
    "        x = self.layers[0].act(self.layers[0].norm(x))\n",
    "        x = F.dropout(x, p=0.1, training=self.training)\n",
    "\n",
    "        return (x @ x.t()).sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "741f839b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 28\n",
    "# num_features = dataset.num_features\n",
    "hidden_channels = 64\n",
    "\n",
    "\n",
    "lr = 0.0000000001\n",
    "epochs = 1500\n",
    "beta = 1\n",
    "\n",
    "\n",
    "model = DeepGCNModel(hidden_channels, num_layers)\n",
    "# model = torch.load(\"./models1/GatedGCN_6_4e-05_Adam_200_2_60.pt\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "train_data = list(map(lambda x: x.to(device), train_data))\n",
    "val_data = list(map(lambda x: x.to(device), val_data))\n",
    "print(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "# optimizer = torch.optim.Adagrad(model.parameters(), lr=lr)\n",
    "# optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "# optimizer = torch.optim.Adamax(model.parameters(), lr=lr)\n",
    "# optimizer = torch.optim.Adadelta(model.parameters(), lr=lr)\n",
    "\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# criterion = torch.nn.BCELoss()\n",
    "# criterion = torch.nn.BCEWithLogitsLoss()\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "# criterion = torch.nn.KLDivLoss()\n",
    "\n",
    "# def RMSELoss(y_pred, y_true):\n",
    "#     return torch.sqrt(torch.mean((y_pred - y_true) ** 2))\n",
    "\n",
    "criterion = f_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "79405b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"DeepGCN_\" + str(num_layers) + \"_\" + str(lr) + \"_\" + \"Adam_\" + str(hidden_channels) + \"_\" + str(beta)\n",
    "\n",
    "\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"secondary_structure_prediction1\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": lr,\n",
    "    \"architecture\": \"DeepGCN\",\n",
    "    \"epochs\": epochs,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"hidden_channels\": hidden_channels,\n",
    "    \"loss\": \"f_loss\",\n",
    "    \"beta\": beta,\n",
    "    \"train:val:test\": \"655:218:218\"\n",
    "    },\n",
    "    name=run_name\n",
    ")\n",
    "\n",
    "epsilon = 1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ad9b0229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        train_recall = []\n",
    "        train_precision = []\n",
    "        for g in tqdm(train_data, ncols=100):\n",
    "            g.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            out = model(g.x, g.edge_index)\n",
    "            y_true = g.adj_mat\n",
    "            loss = criterion(out, y_true.to(torch.float32))            \n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "#             out = out.sigmoid()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "            train_precision.append(precision(out, y_true).item())\n",
    "            train_recall.append(recall(out, y_true).item())\n",
    "            \n",
    "        train_prec = np.mean(train_precision)\n",
    "        train_rec = np.mean(train_recall)\n",
    "        train_f1 = (2 * train_prec * train_rec) / (train_prec + train_rec)\n",
    "        print(f'Epoch: {epoch:03d}, loss: {np.mean(train_loss)}, f1: {train_f1}, precision: {train_prec}, recall: {train_rec}')\n",
    "        \n",
    "        val_loss = []\n",
    "        val_recall = []\n",
    "        val_precision = []\n",
    "        with torch.no_grad():\n",
    "            for g in tqdm(val_data, ncols=100):\n",
    "                g.to(device)\n",
    "                out = model(g.x, g.edge_index)\n",
    "        \n",
    "                y_true = g.adj_mat\n",
    "                loss = criterion(out, y_true.to(torch.float32))\n",
    "                                \n",
    "                val_loss.append(loss.item())\n",
    "                \n",
    "#                 out = out.sigmoid()\n",
    "                \n",
    "                val_precision.append(precision(out, y_true).item())\n",
    "                val_recall.append(recall(out, y_true).item())\n",
    " \n",
    "            \n",
    "            prec = np.mean(val_precision)\n",
    "            rec = np.mean(val_recall)\n",
    "            f1 = (2 * prec * rec) / (prec + rec)\n",
    "            print(f'val_loss: {np.mean(val_loss)}, val_f1: {f1}, val_precision: {prec}, val_recall: {rec}')\n",
    "              \n",
    "            wandb.log({\"train_loss\": np.mean(train_loss), \"train_f1\": train_f1, \"train_precision\": train_prec, \n",
    "                       \"train_recall\": train_rec,\n",
    "                       \"val_loss\": np.mean(val_loss), \"val_f1\": f1, \"val_precision\": prec, \"val_recall\": rec})\n",
    "#     wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "02e9df65",
   "metadata": {},
   "outputs": [],
   "source": [
    "train()\n",
    "torch.save(model, \"./models1/\" + run_name + \"_\" + str(epochs) + \".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad06aa78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
